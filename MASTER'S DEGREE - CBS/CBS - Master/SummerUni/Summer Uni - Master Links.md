## Causal Data Science for Business Decision-making
[[Book of Why Readings]]
#### Lecture 1
Lecture 1 focused on introducing the idea behind causal inference and causality, saying it remains important as it can change the results and interpretations we can gain from data: *There are no definite answers in causal inference --> it depends on the assumptions you have bring and have*
[[Causal Inference]]
[[Causation]]
[[Simpson's Paradox]]
[[Counterfactual Reasoning]]
[[Ladder of Causality]]

### Lecture 2
Lecture 2 focused on why causation is important and how it differs from [[Correlation]]. It then introduced us to the concept of causal models and explained how the idea of causation differs from equations. Finally, the idea behind d-separation was introduced.
[[Ladder of Causality]]
[[Structural Causal Models]]
[[Directed Acyclic Graphs]]
[[D-Separation]]

### Lecture 3
Lecture 3 introduced us to the program of Causalfusion.net, where we examined causal paths (aka directed paths) within causal models. A key point was that there can still be paths even when there is no causal path - these are confounding paths or biased paths.

### Lecture 4
Lecture 4 focused mostly on 

### Lecture 5
Lecture 5 focused mostly on utilising [[Experiment]]s and [[Experimentation]] for ascertaining causal effect. We e.g. looked at how randomization helps deal with confounders, and how experiments and interventions affect the [[Directed Acyclic Graphs]].
[[Randomized Controlled Trials (RCT)]]
[[Interventions in Structural Causal Models]]

### Lecture 6

### Lecture 7
Lecture 7 focused on a more practical aspect of causal data science and [[Causal Inference]]. We were shown how the company Lyft utilises causal inference for their business decisions and how they use interventions to improve their services. 
[[General Notes - Causal Data Science]] (more notes here)

### Lecture 8
Lecture 8 started with an explanation about the relationship between [[Causation]] and [[Artificial Intelligence]]. Basically saying it will lead to [[Counterfactual Reasoning]]. We then looked closer at [[Do-calculus]]. 
[[Counterfactual Reasoning]]
[[Do-calculus]]




## Machine Learning for Predictive Analytics in Business
#### Lecture 1
Lecture 1 introduced what machine learning is and how it can be used it business. Furthermore, it explained why Python was used and how to install it. Also had some general review of relevant mathematics.
[[Machine Learning]]


### Lecture 2
Lecture 2 introduced some basic Python syntax and showed how to handle data in Python. Furthermore, we were introduced to various data structures in Python, as well as various, useful libraries.
[[General Python Syntax]]
[[Python Operators]]
[[Data Structures (Python)]] + [[Data Collection in Python]]
[[Python Libraries]]

### Lecture 3
Lecture 3 focused on data visualization within Python by introducing various tools and libraries for descriptive analytics. 
[[Python Libraries]]
[[Descriptive Analytics (Python)]]

### Lecture 4
Lecture 4 introduced how to perform [[Regression]] within Python, more specifically the linear regression models such as [[OLS Regression]].
[[Linear Regression (Python)]]
[[Regularized Linear Regression]]
[[Polynomial Regression]]
[[train_test_split]]
[[K-fold Cross Validation]]

### Lecture 5
Lecture 5 introduced how to perform [[Logistic Regression]] in Python. 
[[Logistic Regression (Python)]]

### Lecture 6
Lecture 6 focused on artificial neural networks and how they may be used for prediction.
[[Neural Networks]]


### Lecture 7
Lecture 7 focused on how to perform [[K-Nearest Neighbors (Python)]] and [[Naive Bayes (Python)]]
[[K-Nearest Neighbors (Python)]]
[[Naive Bayes (Python)]]

### Lecture 8
Lecture 8 focused on tree-based models, which can be utilised for decision-making and predictions. More specifically we looked at decision trees, random forest, and gradient boosting.
[[Decision Trees]]
[[Tree Pruning]]
[[Ensemble Learning]]
[[Random Forests]]
[[Boosting]]
[[Gradient Boosting]]
[[AdaBoost]]

